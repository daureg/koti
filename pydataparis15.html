<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>A mildly opinionated report of Pydata Paris 2015</title>
  <link href='http://fonts.googleapis.com/css?family=Merriweather:400,400italic,700' rel='stylesheet' type='text/css'>
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
  <link rel="stylesheet" href="normalize.css">
  <!-- <link rel="stylesheet" href="/home/orphee/data/projects/default/static/typeplate.css"> -->
  <link rel="stylesheet" href="default.css">
</head>
<body class="post">
<header>
<h1 class="title">A mildly opinionated report of Pydata Paris 2015</h1>
</header>
<p>Friday, April 3 was rainy in Paris and thus the best time to attend the <a href="http://pydataparis.joinux.org/">PyData conference</a> and get answers to an insistent question: how are Python and its scientific ecosystem a suitable tool to efficiently handle big data on commodity hardware? Below I divided the talks I saw in two parts: first those that directly support that view and then those who present applications in various domains.</p>
<p>By commodity hardware, I mean machines ranging from a recent laptop to a cluster made of a few beefy servers. Despite the promises of distributed solutions like Hadoop, I do believe that, nowadays, the vast majority of data science tasks can still be carry on without resorting to such complex software.</p>
<p>For instance, in my field of graph processing, whereas systems like Google's Pregel <span class="citation" data-cites="Pregel10"><a href="#ref1">[1]</a></span> and open source competitors like <a href="https://giraph.apache.org/">Apache Giraph</a> and <a href="https://dato.com/products/create/">Dato GraphLab</a> are conceptually alluring, researchers have recently questioned whether they are adapted to current problems size (except if you are <a href="https://www.facebook.com/notes/facebook-engineering/scaling-apache-giraph-to-a-trillion-edges/10151617006153920">Facebook</a> or the <a href="http://es.slideshare.net/daniel_bilar/big-graph-analysis-issues-nsa">NSA</a>). These solutions introduce large overheads due to communication cost <span class="citation" data-cites="NativeBenchmark14"><a href="#ref2">[2]</a></span>, thus being <a href="http://www.frankmcsherry.org/graph/scalability/cost/2015/02/04/COST2.html">outperformed by a single laptop even on billion nodes graph</a>, an observation that calls for specialized systems running on one computer with a lot of RAM <span class="citation" data-cites="Ringo15"><a href="#ref3">[3]</a></span>.</p>
<p>That being said, let us proceed to the main matter (<em>which does not include <a href="http://pydataparis.joinux.org/talks.html">the full program</a> nor all the slides and videos: they should <a href="https://twitter.com/PyDataParis">be available soon</a></em>).</p>
<h2 id="efficient-python">Efficient Python</h2>
<h3>Scikit-learn</h3>
<p>The initial keynote was delivered by <a href="http://gael-varoquaux.info/about.html">Gaël Varoquaux</a>, one of the creator of <a href="http://scikit-learn.org/">scikit-learn</a> <span class="citation" data-cites="Scikit12"><a href="#ref4">[4]</a></span>. After a 15 minutes introduction to machine learning (!), he explained the philosophy behind scikit-learn. This library aims to be a universal package allowing anyone to apply widely accepted machine learning methods on any kind of data. Thus, it should be relevant in all domains, from robotics to computer vision through natural language processing and even economics and astrophysics (although this requires specialized packages built on top of it). Ideally, it should also appeal to people coming from non Python languages, meaning the API is designed to be simple and consistent.</p>
<p>Another striking idea was that, contrary to academia, where a 0.1% accuracy improvement justifies a 10 fold increase in algorithm complexity, scikit-learn is aimed at industry. Practitioners there want to rely on simple, well tested methods that work reasonably on a wide range of data. In other words, the machine learning part is supposed to be boring and without surprise, for the challenges stem from data acquisition and results exploitation.</p>
<p>Gaël also explained scikit-learn development process, which I found quite impressive. There are 12 core maintainers and more than 200 contributors. Each proposed change is discussed at length to determine whether it should be included, to assess the code and documentation quality and so on. This quality assurance process also takes the form of extensive testing, with 94% test coverage. All in all, after a few years, this project is now mature (and has an <a href="https://www.openhub.net/p/scikit-learn/estimated_cost">estimated development cost of 6.5M$</a>, which is fairly high for an open source academic software). <em>Note: this was loosely based on <a href="http://fr.slideshare.net/GaelVaroquaux/simple-big-data-in-python">previous slides</a></em>.</p>
<p>To come back to this idea that Python can handle large volume of data on modest machine, I also discovered another aspect of scikit-learn, its online learning ability. That is, some algorithms have the ability to learn incrementally and, therefore, can cope with dataset of arbitrary size (since they can even be streamed from a remote source). In practice, one uses the <code>partial_fit</code> method, after having read <a href="http://scikit-learn.org/stable/modules/scaling_strategies.html#incremental-learning">the relevant documentation</a>.</p>
<p>There was also a discussion on speed. Despite the bad reputation of Python with that respect, scikit-learn meticulous development yields fast implementation. An example of fast and parameter-less algorithm in scikit-learn is <a href="http://en.wikipedia.org/wiki/Random_forest">random forest</a> (which according to large 2014 survey is among the most accurate methods on a broad range of datasets <span class="citation" data-cites="JMLR:v15:delgado14a"><a href="#ref5">[5]</a></span>). Through <a href="http://orbi.ulg.be/bitstream/2268/171887/1/slides.pdf">careful optimizations</a>, random forest in scikit-learn are now competitive with all open source alternatives, regardless of the language. (<em>By the way, these optimizations are the work of <a href="http://www.montefiore.ulg.ac.be/~glouppe/">Gilles Louppe</a>, who wrote his <a href="http://www.montefiore.ulg.ac.be/~glouppe/pdf/phd-thesis.pdf">PhD Thesis</a> on random forest and also happened to give a talk on <a href="https://github.com/glouppe/talk-pydata2015/blob/master/slides.pdf">Tree models with scikit-learn: great learners with little assumptions</a> that I did not attend</em>)</p>
<h3>Other performance talks</h3>
<p>Whereas decision trees naturally provide explainable results, random forest are more opaque. Yet there is a growing trend on <a href="http://towcenter.org/algorithmic-accountability-2/">algorithmic accountability</a> and there may soon be <a href="http://www.nextinpact.com/news/89774-conseil-detat-vers-encadrement-algorithmes-predictifs-en-france.htm" title="In French">laws requiring that decisions based on machine-learned models must be explainable by human operators</a> (in French). This requirement is <a href="http://www.itworld.com/article/2908375/the-ftc-is-worried-about-algorithmic-transparency-and-you-should-be-too.html">taken seriously by the U.S Federal Trade Commission</a> or insurance companies such as AXA, as they must justify that refusing a loan or raising their premium was done ethically, without discrimination and in compliance with the current regulations. Thus, AXA Data Innovation Lab gave a talk on <a href="https://speakerdeck.com/kriss/whitening-the-blackbox-why-and-how-to-explain-machine-learning-predictions">Whitening The Blackbox: Why And How To Explain Machine Learning Predictions?</a></p>
<p>The closing keynote by <a href="https://twitter.com/francescalted">Francesc Alted</a> was titled <a href="https://speakerdeck.com/francescalted/new-trends-in-storing-large-data-silos-with-python">New Trends In Storing Large Data Silos With Python</a>. Its thesis is that the main strength of Python is its interactivity but that to stay relevant, it needs to take advantage of two recent hardware progresses. First, increased parallelism with multi core CPU and SIMD instructions. Second, deeper hierarchical memory with the introduction of L3 cache in CPU and SSD for fast storage (<em>using the <a href="https://en.wikipedia.org/wiki/NVM_Express">NVMe protocol</a> on a PCIe port, SSD drive can be read and written at a rate of two or three gigabytes per second</em>). To exploit this new context, he presented his library, <a href="http://bcolz.blosc.org/intro.html#bcolz-at-glance">Bcolz</a>, which is a data container supporting chunked access and on-the-fly compression.</p>
<p>Along the same line, Kirill Smelkov from Nexedi talked about <a href="http://www.wendelin.io/NXD-Wendelin.Core.Non.Secret">Out-of-core NumPy arrays without changing your code with wendelin-core</a>. It was quite low level for me but the underlying idea was to stream large NumPy arrays from disk to main memory through a custom userspace virtual memory manager. This allow computing transparently the average of a 120GB array on a single laptop, albeit quite slowly for now. For those wanting to know more, <a href="https://lab.nexedi.cn/nexedi/wendelin.core">the code is available</a>.</p>
<p>Then there was two presentations on accelerating Python through compilation.</p>
<p>The first one, by <a href="http://serge.liyun.free.fr/serge/">Serge Guelton</a> &amp; <a href="http://fr.viadeo.com/fr/profile/pierrick.brunet">Pierrick Brunet</a>, introduced <a href="https://pythonhosted.org/pythran/index.html">Pythran</a>. It is a tool taking Python 2.7 high level code and turning it into high level C++11 code, which is then optimized for a given CPU by one's favorite compiler. It does not require the user to unroll loops, but simply to annotate the code with type description. Despite being a two men project, Pythran is tested quite extensively on real code from StackOverflow and the benchmark suites of other compilers.</p>
<p>The second one, by <a href="https://www.linkedin.com/in/pitrou">Antoine Pitrou</a>, focused on <a href="http://numba.pydata.org/">Numba</a>, which transforms Python bytecode to LLVM intermediate representation in a JIT fashion. It support a larger subset of Python than Pythran, can target GPU and does not require type annotation since they are inferred at runtime.</p>
<p>Finally, <a href="https://nl.linkedin.com/in/nielszeilemaker">Niels Zeilemaker</a> described <a href="https://github.com/godatadriven/parallel-connection">a simple approach to parallelize connections to a pool of Postgres servers</a>, which results in linear speed up.</p>
<h2 id="a-typical-data-science-process">A typical data science process</h2>
<p>Real world projects include four steps: getting the data, cleaning them, running algorithm on it and visualizing the results. This was covered in the following talks:</p>
<ul>
<li><a href="https://speakerdeck.com/ianozsvald/cleaning-confused-collections-of-characters">Cleaning Confused Collections of Characters</a> by <a href="http://ianozsvald.com/about-me/">Ian Ozsvald</a>. This talk was about pre processing text data gathered from the wild. It encompassed encoding issue in plain text, parsing HTML, making sense of PDF, normalizing strings and so on. There was many links to libraries but it would be tedious to enumerate all of them so here is a representative selection:
<ul>
<li><a href="https://dedupe.readthedocs.org/en/latest/">Dedupe</a>: perform de-duplication and entity resolution quickly on structured data;</li>
<li><a href="https://github.com/CeON/CERMINE">CERMINE</a>: extract metadata and content from PDF files containing academic publications;</li>
<li><a href="https://ftfy.readthedocs.org/en/latest/">ftfy: fixes text for you</a>: make unicode text representation consistent and possibly less broken.</li>
</ul>
<p>He also teased his next project, a web tool that learned from a small set of examples how to robustly extract relevant information from snippet of real world text. <a href="http://annotate.io/">Check out the alpha</a>!</p></li>
<li><p><a href="https://cs-with-python.github.io/#/">Rush Hour Dynamics: Simulating and visualising commuter flow through the London Underground using graphtool and bokeh</a>, a cool side project of <a href="https://winterflower.github.io/about/">Camilla Montonen</a>: after manually creating a list of all underground stations and their connections, she used <a href="http://graph-tool.skewed.de/">graph-tool</a> to compute the <a href="https://en.wikipedia.org/wiki/Betweenness_centrality">betweenness</a> of nodes. Then she studied how removing one node affect the commuter flow and interactively visualized the results with <a href="http://bokeh.pydata.org/en/latest/">Bokeh</a>.</p></li>
</ul>
<ul>
<li>Finally, <a href="http://cazencott.info/dotclear/public/publications/2015-04-03-PyData_Azencott.pdf">Reaching your DREAMs with Python</a> by <a href="http://cazencott.info/">Chloé-Agathe Azencott</a> illustrated computational biology applications through two examples, <a href="https://www.synapse.org/#!Synapse:syn1761567">predicting the toxicity of a chemical on a given cell line</a> and <a href="https://www.synapse.org/#!Synapse:syn1734172">predicting the response of patients to rhematoid arthritis treatment</a>. Unfortunately, given my background and the short length of the talk, I did not quite get the biology part. The things I can recall: the use of hdf5 as exchange format if not all team members are on the NumPy stack, scikit-learn and <a href="https://sheffieldml.github.io/GPy/">GPy</a> (a Gaussian processes framework) provide solid foundations to develop more specialized algorithms driven by domain knowledge, and visualization plays a large role at every stage.</li>
</ul>
<figure>
<img id="figtoxy" src="toxygenetic.png" alt="A visual description of the first task. Note that as typical in biological application, the number of features (here 10K and 1.3M) is very large compared with the number of instances (156 and 884)." /><figcaption>A visual description of the first task. Note that typically in biological application, the number of features (here 10K and 1.3M) is very large compared with the number of instances (156 and 884).</figcaption>
</figure>
<div class="references">
<h2 id="references" class="unnumbered">References</h2>
<p id="ref1">[1] G. Malewicz, M. H. Austern, A. J. Bik, J. C. Dehnert, I. Horn, N. Leiser, and G. Czajkowski, “Pregel: a system for large-scale graph processing,” in <em>Proceedings of the 2010 international conference on Management of data - SIGMOD ’10</em>, 2010, p. 135 [Online]. Available: <a href="http://dl.acm.org/citation.cfm?id=1807184" class="uri">http://dl.acm.org/citation.cfm?id=1807184</a></p>
<p id="ref2">[2] N. Satish, N. Sundaram, M. M. A. Patwary, J. Seo, J. Park, M. A. Hassaan, S. Sengupta, Z. Yin, and P. Dubey, “Navigating the Maze of Graph Analytics Frameworks Using Massive Graph Datasets,” in <em>Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data</em>, 2014, pp. 979–990 [Online]. Available: <a href="http://doi.acm.org/10.1145/2588555.2610518" class="uri">http://doi.acm.org/10.1145/2588555.2610518</a></p>
<p id="ref3">[3] Y. Perez, R. Sosic, A. Banerjee, R. Puttagunta, M. Raison, P. Shah, and J. Leskovec, “Ringo: Interactive Graph Analytics on Big-Memory Machines,” p. 6, Mar. 2015 [Online]. Available: <a href="http://arxiv.org/abs/1503.07881" class="uri">http://arxiv.org/abs/1503.07881</a></p>
<p id="ref4">[4] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and É. Duchesnay, “Scikit-learn: Machine Learning in Python,” <em>Journal of Machine Learning Research</em>, vol. 12, pp. 2825–2830, 2012 [Online]. Available: <a href="http://jmlr.org/papers/v12/pedregosa11a.html" class="uri">http://jmlr.org/papers/v12/pedregosa11a.html</a></p>
<p id="ref5">[5] M. Fernández-Delgado, E. Cernadas, S. Barro, and D. Amorim, “Do we Need Hundreds of Classifiers to Solve Real World Classification Problems?” <em>Journal of Machine Learning Research</em>, vol. 15, pp. 3133–3181, 2014 [Online]. Available: <a href="http://jmlr.org/papers/v15/delgado14a.html" class="uri">http://jmlr.org/papers/v15/delgado14a.html</a></p>
</div>
</body>
</html>
